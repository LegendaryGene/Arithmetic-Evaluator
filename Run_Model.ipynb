{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imutils import contours\n",
    "import imutils\n",
    "import cv2 \n",
    "import numpy as np\n",
    "import torch\n",
    "import cv2\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from pandas.core.common import flatten\n",
    "from torchvision import datasets, transforms, models\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import torchvision.transforms.functional as TF\n",
    "import random\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper(Network,self).__init__()\n",
    "\t\tself.cl1=nn.Conv2d(1,16,3,padding=1)\n",
    "\t\tself.cl1_bn=nn.BatchNorm2d(16)\n",
    "\t\tself.cl2=nn.Conv2d(16,32,3,padding=1)\n",
    "\t\tself.cl2_bn=nn.BatchNorm2d(32)\n",
    "\t\tself.cl3=nn.Conv2d(32,64,3,padding=1)\n",
    "\t\tself.cl3_bn=nn.BatchNorm2d(64)\n",
    "\t\tself.dropout=nn.Dropout(0.2)\n",
    "\t\tself.fc1=nn.Linear(4096,1024)\n",
    "\t\tself.fc1_bn=nn.BatchNorm1d(1024)\n",
    "\t\tself.fc2=nn.Linear(1024,256)\n",
    "\t\tself.fc2_bn=nn.BatchNorm1d(256)\n",
    "\t\tself.fc3=nn.Linear(256,14)\n",
    "\t\tself.pool=nn.MaxPool2d(2,2)\n",
    "\n",
    "\tdef forward(self,x):\n",
    "\t\tx=self.cl1(x)\n",
    "\t\tx=self.pool(F.leaky_relu(self.cl1_bn(x)))\n",
    "\t\tx=self.cl2(x)\n",
    "\t\tx=self.pool(F.leaky_relu(self.cl2_bn(x)))\n",
    "\t\tx=self.cl3(x)\n",
    "\t\tx=self.pool(F.leaky_relu(self.cl3_bn(x)))\n",
    "\t\tx=x.view(-1,4096)\n",
    "\t\tself.dropout(x)\n",
    "\t\tx=self.fc1(x)\n",
    "\t\tx=F.relu(self.fc1_bn(x))\n",
    "\t\tself.dropout(x)\n",
    "\t\tx=self.fc2(x)\n",
    "\t\tx=F.relu(self.fc2_bn(x))\n",
    "\t\tself.dropout(x)\n",
    "\t\tx=self.fc3(x)\n",
    "\t\treturn x\n",
    "\n",
    "model=Network()\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('/home/legendarygene/Desktop/Handwritten Arithmetic Calculator/model_ERA_lr0005.pt'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_test = transforms.Compose([transforms.Resize((64,64)),\n",
    "\t\t\t\t\t\t\t\t\t transforms.Grayscale(),\n",
    "\t\t\t\t\t\t\t\t\t transforms.ToTensor(),\n",
    "\t\t\t\t\t\t\t\t\t transforms.Normalize((0.5), (0.5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes=['+','-','0','1','2','3','4','5','6','7','8','9','/','*']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"/home/legendarygene/Desktop/Handwritten Arithmetic Calculator/Final Testing/image.jpeg\"\n",
    "image = cv2.imread(path)\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "_,img=cv2.threshold(gray,150,255,cv2.THRESH_BINARY_INV)\n",
    "cnts = cv2.findContours(img, cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "cnts = imutils.grab_contours(cnts)\n",
    "digitCnts = []\n",
    "\n",
    "for c in cnts:\n",
    "    (x, y, w, h) = cv2.boundingRect(c)\n",
    "    digitCnts.append(c)\n",
    "digitCnts = contours.sort_contours(digitCnts,method=\"left-to-right\")[0]\n",
    "symbols = []\n",
    "to_calculate = []\n",
    "\n",
    "for c in digitCnts:\n",
    "    (x, y, w, h) = cv2.boundingRect(c)\n",
    "    roi = img[y:y + h, x:x + w]\n",
    "    _,roi = cv2.threshold(roi,200,255,cv2.THRESH_BINARY_INV)\n",
    "    index = 0\n",
    "    if roi.shape[0] > roi.shape[1]:\n",
    "        index = roi.shape[0]\n",
    "        diff = roi.shape[0] - roi.shape[1]\n",
    "        roi = cv2.copyMakeBorder(roi, 0, 0, diff//2, diff//2,cv2.BORDER_CONSTANT ,value=255)\n",
    "    elif roi.shape[1] > roi.shape[0]:\n",
    "        index = roi.shape[1]\n",
    "        diff = roi.shape[1] - roi.shape[0]\n",
    "        roi = cv2.copyMakeBorder(roi, diff//2, diff//2,0 ,0 ,cv2.BORDER_CONSTANT, value=255)\n",
    "    roi = cv2.copyMakeBorder(roi, 0, 0, diff//2, diff//2,cv2.BORDER_CONSTANT, value=255)\n",
    "    roi = cv2.copyMakeBorder(roi, index//10,index//10,index//10,index//10,cv2.BORDER_CONSTANT, value=255)\n",
    "    # cv2.imshow(\"Image\",roi)\n",
    "    # cv2.waitKey(5000)\n",
    "    roi = np.asarray(roi,dtype = np.float32)\n",
    "    roi = TF.to_pil_image(roi)\n",
    "    roi = transform_test(roi)\n",
    "    roi = roi.view(1,1,64,64)\n",
    "    symbols.append(model(roi.cuda()))\n",
    "# cv2.destroyAllWindows()\n",
    "\n",
    "stringexp = \"\"\n",
    "for val in symbols:\n",
    "    idx = torch.max(val,1)[1]\n",
    "    to_calculate.append(classes[idx])\n",
    "    stringexp += classes[idx]\n",
    "\n",
    "print(stringexp)\n",
    "ans = eval(stringexp)\n",
    "print(ans)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Aadvik_ke_boobs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0d6d5e06e70d13f8fb9c7dacc9b31ee65d70f7b12fae679e8dfe9dc9857e2671"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
